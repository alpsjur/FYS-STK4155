\section{Theory}
\label{sec:theory}

\subsection{Ordinary least squares}

\subsection{Ridge regression}
	
\subsection{Lasso regression}

\subsection{Mean squared error}

\subsection{Score function}

\subsection{k-fold cross validation}
There are several methods for estimating the skill of a machine learning model. One such method is the $k$-fold cross-validation procedure, which is used when working with a limited data sample. The idea is to divide the data sample into $k$ groups or folds, and then retain some of the data to use as a test set after fitting a model to the remaining data.  

\begin{algorithm}[htbp]\label{alg:met}\caption{The $k$-fold cross-validation algorithm.}
	\SetAlgoLined
	\BlankLine
	\BlankLine
	Shuffle the dataset randomly\;
	Divide the dataset into $k$ folds\;
	\ForEach{$k$}{
		Take the $k$th fold out to use as test data set\;
		Set the remaining folds as training data set\;
		Fit a model to the training set\;
		Evaluate the model on the test set\;
		Retain the evaluation score and discard the model \;
	}
	Calculate the mean of the evaluation scores\;	
	\BlankLine
	\BlankLine
\end{algorithm}


% Eksempel for store matriser
\[A =
\mqty[b_1 & c_1 & 0 & \hdots & \hdots & 0 \\
a_1 & b_2 & c_2 & 0 & \hdots & 0 \\
0 & a_2 & b_3 & c_3 & \hdots & 0 \\
\vdots & \ddots & \ddots & \ddots & \ddots & \vdots \\
0 & \hdots & \ddots & a_{n-2} & b_{n-1} & c_{n-1} \\
0 & \hdots & \hdots & 0 & a_{n-1} & b_n],
\]