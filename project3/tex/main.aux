\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{yi2004neural}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:introduction}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Theory and implementation}{1}{section.2}\protected@file@percent }
\newlabel{sec:theory}{{2}{1}{Theory and implementation}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The general problem}{1}{subsection.2.1}\protected@file@percent }
\newlabel{eq:diffusionEQ}{{1}{1}{The general problem}{equation.2.1}{}}
\newlabel{eq:initialCondition}{{2}{1}{The general problem}{equation.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Exact solution of the diffusion equation}{2}{subsection.2.2}\protected@file@percent }
\newlabel{eq:separated}{{3}{2}{Exact solution of the diffusion equation}{equation.2.3}{}}
\newlabel{eq:exact}{{4}{2}{Exact solution of the diffusion equation}{equation.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Discretization of the diffusion equation}{2}{subsection.2.3}\protected@file@percent }
\newlabel{eq:FE}{{5}{2}{Discretization of the diffusion equation}{equation.2.5}{}}
\newlabel{eq:CD}{{6}{2}{Discretization of the diffusion equation}{equation.2.6}{}}
\citation{prosjekt2}
\citation{lagaris1998artificial}
\citation{yi2004neural}
\citation{yi2004neural}
\newlabel{eq:theAlgorithm}{{8}{3}{Discretization of the diffusion equation}{equation.2.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Solving PDEs with Neural Networks}{3}{subsection.2.4}\protected@file@percent }
\newlabel{eq:errorFunc}{{9}{3}{Solving PDEs with Neural Networks}{equation.2.9}{}}
\newlabel{eq:trialFunction}{{10}{3}{Solving PDEs with Neural Networks}{equation.2.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Computing eigenpairs with Neural Networks}{3}{subsection.2.5}\protected@file@percent }
\newlabel{eq:eigenDE}{{11}{3}{Computing eigenpairs with Neural Networks}{equation.2.11}{}}
\newlabel{eq:f}{{12}{3}{Computing eigenpairs with Neural Networks}{equation.2.12}{}}
\newlabel{eq:find_w}{{2.5}{3}{Computing eigenpairs with Neural Networks}{equation.2.12}{}}
\newlabel{eq:trial_eigen}{{13}{4}{Computing eigenpairs with Neural Networks}{equation.2.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Implementing the Neural Network}{4}{subsection.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{4}{section.3}\protected@file@percent }
\newlabel{sec:results}{{3}{4}{Results}{section.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Time evolution of eq. \ref  {eq:diffusionEQ} solved using finite difference methods: CD and FE. For each point in time a visual comparison is made with the exact solution, represented by dashed lines, as well as a run with higher spatial resolution, represented by different colours.\relax }}{4}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:FDcompare}{{1}{4}{Time evolution of eq. \ref {eq:diffusionEQ} solved using finite difference methods: CD and FE. For each point in time a visual comparison is made with the exact solution, represented by dashed lines, as well as a run with higher spatial resolution, represented by different colours.\relax }{figure.caption.1}{}}
\bibstyle{plainnat}
\bibdata{ourbib}
\bibcite{prosjekt2}{{1}{2019}{{J\IeC {\o }rgensen et~al.}}{{J\IeC {\o }rgensen, Sjur, and Kallmyr}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Time evolution of eq. \ref  {eq:diffusionEQ} solved using a neural network. For both instants in time, a visual comparison is made with the exact solution, represented by dashed lines.\relax }}{5}{figure.caption.2}\protected@file@percent }
\newlabel{fig:NNcompare}{{2}{5}{Time evolution of eq. \ref {eq:diffusionEQ} solved using a neural network. For both instants in time, a visual comparison is made with the exact solution, represented by dashed lines.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Shown on the left-hand side, top-to-bottom (a., c.), are the MSE's as a function of temporal resolution, obtained from using finite difference methods for $t=0.02$ and $t=0.3$, respectively. Likewise, on the right-hand side (b., d.) the MSE's yielded from the neural network are shown as a function of iterations with network parameters $N_t = 10$, $N_x = 100$, and $\gamma = 0.004$.\relax }}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig:MSEbench}{{3}{5}{Shown on the left-hand side, top-to-bottom (a., c.), are the MSE's as a function of temporal resolution, obtained from using finite difference methods for $t=0.02$ and $t=0.3$, respectively. Likewise, on the right-hand side (b., d.) the MSE's yielded from the neural network are shown as a function of iterations with network parameters $N_t = 10$, $N_x = 100$, and $\gamma = 0.004$.\relax }{figure.caption.3}{}}
\bibcite{lagaris1998artificial}{{2}{1998}{{Lagaris et~al.}}{{Lagaris, Likas, and Fotiadis}}}
\bibcite{yi2004neural}{{3}{2004}{{Yi et~al.}}{{Yi, Fu, and Tang}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Shown on the left-hand side, top-to-bottom (a., c.), are the CPU time's as a function of temporal resolution, obtained from using finite difference methods for $t=0.02$ and $t=0.3$, respectively. Likewise, on the right-hand side (b., d.) the CPU time's yielded from the neural network are shown as a function of iterations with network parameters $N_t = 10$, $N_x = 100$, and $\gamma = 0.004$.\relax }}{6}{figure.caption.4}\protected@file@percent }
\newlabel{fig:CPUbench}{{4}{6}{Shown on the left-hand side, top-to-bottom (a., c.), are the CPU time's as a function of temporal resolution, obtained from using finite difference methods for $t=0.02$ and $t=0.3$, respectively. Likewise, on the right-hand side (b., d.) the CPU time's yielded from the neural network are shown as a function of iterations with network parameters $N_t = 10$, $N_x = 100$, and $\gamma = 0.004$.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Figure showing how the value of the elements of the estimated eigenvector $v_{max}$ evolves over time. Each line represents one of the elements of the vector.\relax }}{6}{figure.caption.5}\protected@file@percent }
\newlabel{fig:eigenvector_max}{{5}{6}{Figure showing how the value of the elements of the estimated eigenvector $v_{max}$ evolves over time. Each line represents one of the elements of the vector.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{6}{section.4}\protected@file@percent }
\newlabel{sec:discussion}{{4}{6}{Discussion}{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{6}{section.5}\protected@file@percent }
\newlabel{sec:conclusion}{{5}{6}{Conclusion}{section.5}{}}
